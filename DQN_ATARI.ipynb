{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8303c7ff-9577-4ab0-a413-185ce3c227e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0bfb6d3-d8b3-42aa-9c69-ccceb85d1621",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym[atari] in c:\\users\\ananya\\appdata\\roaming\\python\\python39\\site-packages (0.19.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in d:\\anaconda3\\envs\\skynet\\lib\\site-packages (from gym[atari]) (1.21.5)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in c:\\users\\ananya\\appdata\\roaming\\python\\python39\\site-packages (from gym[atari]) (1.6.0)\n",
      "Collecting opencv-python>=3.\n",
      "  Using cached opencv_python-4.5.5.62-cp36-abi3-win_amd64.whl (35.4 MB)\n",
      "Collecting atari-py==0.2.6\n",
      "  Using cached atari_py-0.2.6-cp39-cp39-win_amd64.whl\n",
      "Requirement already satisfied: six in d:\\anaconda3\\envs\\skynet\\lib\\site-packages (from atari-py==0.2.6->gym[atari]) (1.16.0)\n",
      "Installing collected packages: opencv-python, atari-py\n",
      "Successfully installed atari-py-0.2.6 opencv-python-4.5.5.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The candidate selected for download or install is a yanked version: 'atari-py' candidate (version 0.2.6 at https://files.pythonhosted.org/packages/43/dd/2721f34a89dc520d2e09363fd23d110a33bbab2399e50fdced6eb2ed2157/atari-py-0.2.6.tar.gz#sha256=6249ad5079b0489e87eb44e65485bb1b07cc1b5af729f1ee52ece749503ceb1d (from https://pypi.org/simple/atari-py/))\n",
      "Reason for being yanked: re-release with new wheels\n"
     ]
    }
   ],
   "source": [
    "!pip install gym[atari]\n",
    "!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "d679b58c-f51e-4da6-a26b-36ee509897cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Using cached tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\envs\\skynet\\lib\\site-packages (from tqdm) (0.4.4)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.62.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e2bb47-5724-4e28-9fdb-d90d2d6ba819",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'D:\\Anaconda3\\envs\\SKYNET\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from atari_py import import_roms\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "from torch.optim import RMSprop\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import DQN\n",
    "import torchvision.transforms.functional as TF\n",
    "from collections import deque\n",
    "from queue import Queue\n",
    "from tqdm import tqdm as tq\n",
    "import random\n",
    "import os\n",
    "from gym.core import Env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80661031-d024-4825-98a4-c19b5f7efcab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__main__'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac3a8fe3-19a9-4dda-a3a1-f43c5f695306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying adventure.bin from .\\Roms\\ROMS\\ROMS\\Adventure (1980) (Atari, Warren Robinett) (CX2613, CX2613P) (PAL).bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\adventure.bin\n",
      "copying air_raid.bin from .\\Roms\\ROMS\\ROMS\\Air Raid (Men-A-Vision) (PAL) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\air_raid.bin\n",
      "copying alien.bin from .\\Roms\\ROMS\\ROMS\\Alien (1982) (20th Century Fox Video Games, Douglas 'Dallas North' Neubauer) (11006) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\alien.bin\n",
      "copying amidar.bin from .\\Roms\\ROMS\\ROMS\\Amidar (1982) (Parker Brothers, Ed Temple) (PB5310) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\amidar.bin\n",
      "copying assault.bin from .\\Roms\\ROMS\\ROMS\\Assault (AKA Sky Alien) (1983) (Bomb - Onbase) (CA281).bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\assault.bin\n",
      "copying asterix.bin from .\\Roms\\ROMS\\ROMS\\Asterix (AKA Taz) (07-27-1983) (Atari, Jerome Domurat, Steve Woita) (CX2696) (Prototype).bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\asterix.bin\n",
      "copying asteroids.bin from .\\Roms\\ROMS\\ROMS\\Asteroids (1981) (Atari, Brad Stewart - Sears) (CX2649 - 49-75163) [no copyright] ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\asteroids.bin\n",
      "copying atlantis.bin from .\\Roms\\ROMS\\ROMS\\Atlantis (Lost City of Atlantis) (1982) (Imagic, Dennis Koble) (720103-1A, 720103-1B, IA3203, IX-010-04) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\atlantis.bin\n",
      "copying bank_heist.bin from .\\Roms\\ROMS\\ROMS\\Bank Heist (Bonnie & Clyde, Cops 'n' Robbers, Hold-Up, Roaring 20's) (1983) (20th Century Fox Video Games, Bill Aspromonte) (11012) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\bank_heist.bin\n",
      "copying battle_zone.bin from .\\Roms\\ROMS\\ROMS\\Battlezone (1983) (Atari - GCC, Mike Feinstein, Brad Rice) (CX2681) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\battle_zone.bin\n",
      "copying beam_rider.bin from .\\Roms\\ROMS\\ROMS\\Beamrider (1984) (Activision - Cheshire Engineering, David Rolfe, Larry Zwick) (AZ-037-04) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\beam_rider.bin\n",
      "copying berzerk.bin from .\\Roms\\ROMS\\ROMS\\Berzerk (1982) (Atari, Dan Hitchens - Sears) (CX2650 - 49-75168) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\berzerk.bin\n",
      "copying bowling.bin from .\\Roms\\ROMS\\ROMS\\Bowling (1979) (Atari, Larry Kaplan - Sears) (CX2628 - 6-99842, 49-75117) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\bowling.bin\n",
      "copying boxing.bin from .\\Roms\\ROMS\\ROMS\\Boxing - La Boxe (1980) (Activision, Bob Whitehead) (AG-002, CAG-002, AG-002-04) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\boxing.bin\n",
      "copying breakout.bin from .\\Roms\\ROMS\\ROMS\\Breakout - Breakaway IV (Paddle) (1978) (Atari, Brad Stewart - Sears) (CX2622 - 6-99813, 49-75107) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\breakout.bin\n",
      "copying carnival.bin from .\\Roms\\ROMS\\ROMS\\Carnival (1982) (Coleco - Woodside Design Associates, Steve 'Jessica Stevens' Kitchen) (2468) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\carnival.bin\n",
      "copying centipede.bin from .\\Roms\\ROMS\\ROMS\\Centipede (1983) (Atari - GCC) (CX2676) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\centipede.bin\n",
      "copying chopper_command.bin from .\\Roms\\ROMS\\ROMS\\Chopper Command (1982) (Activision, Bob Whitehead) (AX-015, AX-015-04) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\chopper_command.bin\n",
      "copying crazy_climber.bin from .\\Roms\\ROMS\\ROMS\\Crazy Climber (1983) (Atari - Roklan, Joe Gaucher, Alex Leavens) (CX2683) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\crazy_climber.bin\n",
      "copying defender.bin from .\\Roms\\ROMS\\ROMS\\Defender (1982) (Atari, Robert C. Polaro, Alan J. Murphy - Sears) (CX2609 - 49-75186) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\defender.bin\n",
      "copying demon_attack.bin from .\\Roms\\ROMS\\ROMS\\Demon Attack (Death from Above) (1982) (Imagic, Rob Fulop) (720000-200, 720101-1B, 720101-1C, IA3200, IA3200C, IX-006-04) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\demon_attack.bin\n",
      "copying donkey_kong.bin from .\\Roms\\ROMS\\ROMS\\Donkey Kong (1982) (Coleco - Woodside Design Associates - Imaginative Systems Software, Garry Kitchen) (2451) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\donkey_kong.bin\n",
      "copying double_dunk.bin from .\\Roms\\ROMS\\ROMS\\Double Dunk (Super Basketball) (1989) (Atari, Matthew L. Hubbard) (CX26159) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\double_dunk.bin\n",
      "copying elevator_action.bin from .\\Roms\\ROMS\\ROMS\\Elevator Action (1983) (Atari, Dan Hitchens) (CX26126) (Prototype) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\elevator_action.bin\n",
      "copying enduro.bin from .\\Roms\\ROMS\\ROMS\\Enduro (1983) (Activision, Larry Miller) (AX-026, AX-026-04) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\enduro.bin\n",
      "copying fishing_derby.bin from .\\Roms\\ROMS\\ROMS\\Fishing Derby (1980) (Activision, David Crane) (AG-004) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\fishing_derby.bin\n",
      "copying freeway.bin from .\\Roms\\ROMS\\ROMS\\Freeway (1981) (Activision, David Crane) (AG-009, AG-009-04) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\freeway.bin\n",
      "copying frogger.bin from .\\Roms\\ROMS\\ROMS\\Frogger (1982) (Parker Brothers, Ed English, David Lamkins) (PB5300) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\frogger.bin\n",
      "copying frostbite.bin from .\\Roms\\ROMS\\ROMS\\Frostbite (1983) (Activision, Steve Cartwright) (AX-031) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\frostbite.bin\n",
      "copying galaxian.bin from .\\Roms\\ROMS\\ROMS\\Galaxian (1983) (Atari - GCC, Mark Ackerman, Tom Calderwood, Glenn Parker) (CX2684) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\galaxian.bin\n",
      "copying gopher.bin from .\\Roms\\ROMS\\ROMS\\Gopher (Gopher Attack) (1982) (U.S. Games Corporation - JWDA, Sylvia Day, Todd Marshall, Robin McDaniel, Henry Will IV) (VC2001) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\gopher.bin\n",
      "copying gravitar.bin from .\\Roms\\ROMS\\ROMS\\Gravitar (1983) (Atari, Dan Hitchens, Mimi Nyden) (CX2685) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\gravitar.bin\n",
      "copying hero.bin from .\\Roms\\ROMS\\ROMS\\H.E.R.O. (1984) (Activision, John Van Ryzin) (AZ-036-04) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\hero.bin\n",
      "copying ice_hockey.bin from .\\Roms\\ROMS\\ROMS\\Ice Hockey - Le Hockey Sur Glace (1981) (Activision, Alan Miller) (AX-012, CAX-012, AX-012-04) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\ice_hockey.bin\n",
      "copying jamesbond.bin from .\\Roms\\ROMS\\ROMS\\James Bond 007 (James Bond Agent 007) (1984) (Parker Brothers - On-Time Software, Joe Gaucher, Louis Marbel) (PB5110) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\jamesbond.bin\n",
      "copying journey_escape.bin from .\\Roms\\ROMS\\ROMS\\Journey Escape (1983) (Data Age, J. Ray Dettling) (112-006) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\journey_escape.bin\n",
      "copying kaboom.bin from .\\Roms\\ROMS\\ROMS\\Kaboom! (Paddle) (1981) (Activision, Larry Kaplan, David Crane) (AG-010, AG-010-04) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\kaboom.bin\n",
      "copying kangaroo.bin from .\\Roms\\ROMS\\ROMS\\Kangaroo (1983) (Atari - GCC, Kevin Osborn) (CX2689) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\kangaroo.bin\n",
      "copying keystone_kapers.bin from .\\Roms\\ROMS\\ROMS\\Keystone Kapers - Raueber und Gendarm (1983) (Activision, Garry Kitchen - Ariola) (EAX-025, EAX-025-04I - 711 025-725) (PAL).bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\keystone_kapers.bin\n",
      "copying king_kong.bin from .\\Roms\\ROMS\\ROMS\\King Kong (1982) (Tigervision - Software Electronics Corporation, Karl T. Olinger - Teldec) (7-001 - 3.60001 VE) (PAL).bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\king_kong.bin\n",
      "copying koolaid.bin from .\\Roms\\ROMS\\ROMS\\Kool-Aid Man (Kool Aid Pitcher Man) (1983) (M Network, Stephen Tatsumi, Jane Terjung - Kool Aid) (MT4648) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\koolaid.bin\n",
      "copying krull.bin from .\\Roms\\ROMS\\ROMS\\Krull (1983) (Atari, Jerome Domurat, Dave Staugas) (CX2682) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\krull.bin\n",
      "copying kung_fu_master.bin from .\\Roms\\ROMS\\ROMS\\Kung-Fu Master (1987) (Activision - Imagineering, Dan Kitchen, Garry Kitchen) (AG-039-04) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\kung_fu_master.bin\n",
      "copying laser_gates.bin from .\\Roms\\ROMS\\ROMS\\Laser Gates (AKA Innerspace) (1983) (Imagic, Dan Oliver) (720118-2A, 13208, EIX-007-04I) (PAL).bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\laser_gates.bin\n",
      "copying lost_luggage.bin from .\\Roms\\ROMS\\ROMS\\Lost Luggage (Airport Mayhem) (1982) (Apollo - Games by Apollo, Larry Minor, Ernie Runyon, Ed Salvo) (AP-2004) [no opening scene] ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\lost_luggage.bin\n",
      "copying montezuma_revenge.bin from .\\Roms\\ROMS\\ROMS\\Montezuma's Revenge - Featuring Panama Joe (1984) (Parker Brothers - JWDA, Henry Will IV) (PB5760) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\montezuma_revenge.bin\n",
      "copying mr_do.bin from .\\Roms\\ROMS\\ROMS\\Mr. Do! (1983) (CBS Electronics, Ed English) (4L4478) (PAL).bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\mr_do.bin\n",
      "copying ms_pacman.bin from .\\Roms\\ROMS\\ROMS\\Ms. Pac-Man (1983) (Atari - GCC, Mark Ackerman, Glenn Parker) (CX2675) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\ms_pacman.bin\n",
      "copying name_this_game.bin from .\\Roms\\ROMS\\ROMS\\Name This Game (Guardians of Treasure) (1983) (U.S. Games Corporation - JWDA, Roger Booth, Sylvia Day, Ron Dubren, Todd Marshall, Robin McDaniel, Wes Trager, Henry Will IV) (VC1007) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\name_this_game.bin\n",
      "copying pacman.bin from .\\Roms\\ROMS\\ROMS\\Pac-Man (1982) (Atari, Tod Frye) (CX2646) (PAL).bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\pacman.bin\n",
      "copying phoenix.bin from .\\Roms\\ROMS\\ROMS\\Phoenix (1983) (Atari - GCC, Mike Feinstein, John Mracek) (CX2673) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\phoenix.bin\n",
      "copying video_pinball.bin from .\\Roms\\ROMS\\ROMS\\Pinball (AKA Video Pinball) (Zellers).bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\video_pinball.bin\n",
      "copying pitfall.bin from .\\Roms\\ROMS\\ROMS\\Pitfall! - Pitfall Harry's Jungle Adventure (Jungle Runner) (1982) (Activision, David Crane) (AX-018, AX-018-04) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\pitfall.bin\n",
      "copying pooyan.bin from .\\Roms\\ROMS\\ROMS\\Pooyan (1983) (Konami) (RC 100-X 02) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\pooyan.bin\n",
      "copying private_eye.bin from .\\Roms\\ROMS\\ROMS\\Private Eye (1984) (Activision, Bob Whitehead) (AG-034-04) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\private_eye.bin\n",
      "copying qbert.bin from .\\Roms\\ROMS\\ROMS\\Q-bert (1983) (Parker Brothers - Western Technologies, Dave Hampton, Tom Sloper) (PB5360) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\qbert.bin\n",
      "copying riverraid.bin from .\\Roms\\ROMS\\ROMS\\River Raid (1982) (Activision, Carol Shaw) (AX-020, AX-020-04) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\riverraid.bin\n",
      "copying road_runner.bin from patched version of .\\Roms\\ROMS\\ROMS\\Road Runner (1989) (Atari - Bobco, Robert C. Polaro) (CX2663) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\road_runner.bin\n",
      "copying robotank.bin from .\\Roms\\ROMS\\ROMS\\Robot Tank (Robotank) (1983) (Activision, Alan Miller) (AZ-028, AG-028-04) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\robotank.bin\n",
      "copying seaquest.bin from .\\Roms\\ROMS\\ROMS\\Seaquest (1983) (Activision, Steve Cartwright) (AX-022) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\seaquest.bin\n",
      "copying sir_lancelot.bin from .\\Roms\\ROMS\\ROMS\\Sir Lancelot (1983) (Xonox - K-Tel Software - Product Guild, Anthony R. Henderson) (99006, 6220) (PAL).bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\sir_lancelot.bin\n",
      "copying skiing.bin from .\\Roms\\ROMS\\ROMS\\Skiing - Le Ski (1980) (Activision, Bob Whitehead) (AG-005, CAG-005, AG-005-04) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\skiing.bin\n",
      "copying solaris.bin from .\\Roms\\ROMS\\ROMS\\Solaris (The Last Starfighter, Star Raiders II, Universe) (1986) (Atari, Douglas Neubauer, Mimi Nyden) (CX26136) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\solaris.bin\n",
      "copying space_invaders.bin from .\\Roms\\ROMS\\ROMS\\Space Invaders (1980) (Atari, Richard Maurer - Sears) (CX2632 - 49-75153) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\space_invaders.bin\n",
      "copying star_gunner.bin from .\\Roms\\ROMS\\ROMS\\Stargunner (1983) (Telesys, Alex Leavens) (1005) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\star_gunner.bin\n",
      "copying surround.bin from .\\Roms\\ROMS\\ROMS\\Surround (32 in 1) (Bit Corporation) (R320).bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\surround.bin\n",
      "copying tennis.bin from .\\Roms\\ROMS\\ROMS\\Tennis - Le Tennis (1981) (Activision, Alan Miller) (AG-007, CAG-007) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\tennis.bin\n",
      "copying time_pilot.bin from .\\Roms\\ROMS\\ROMS\\Time Pilot (1983) (Coleco - Woodside Design Associates, Harley H. Puthuff Jr.) (2663) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\time_pilot.bin\n",
      "copying trondead.bin from .\\Roms\\ROMS\\ROMS\\TRON - Deadly Discs (TRON Joystick) (1983) (M Network - INTV - APh Technological Consulting, Jeff Ronne, Brett Stutz) (MT5662) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\trondead.bin\n",
      "copying tutankham.bin from .\\Roms\\ROMS\\ROMS\\Tutankham (1983) (Parker Brothers, Dave Engman, Dawn Stockbridge) (PB5340) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\tutankham.bin\n",
      "copying up_n_down.bin from .\\Roms\\ROMS\\ROMS\\Up 'n Down (1984) (SEGA - Beck-Tech, Steve Beck, Phat Ho) (009-01) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\up_n_down.bin\n",
      "copying venture.bin from .\\Roms\\ROMS\\ROMS\\Venture (1982) (Coleco, Joseph Biel) (2457) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\venture.bin\n",
      "copying pong.bin from .\\Roms\\ROMS\\ROMS\\Video Olympics - Pong Sports (Paddle) (1977) (Atari, Joe Decuir - Sears) (CX2621 - 99806, 6-99806, 49-75104) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\pong.bin\n",
      "copying wizard_of_wor.bin from .\\Roms\\ROMS\\ROMS\\Wizard of Wor (1982) (CBS Electronics - Roklan, Joe Hellesen, Joe Wagner) (M8774, M8794) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\wizard_of_wor.bin\n",
      "copying yars_revenge.bin from .\\Roms\\ROMS\\ROMS\\Yars' Revenge (Time Freeze) (1982) (Atari, Howard Scott Warshaw - Sears) (CX2655 - 49-75167) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\yars_revenge.bin\n",
      "copying zaxxon.bin from .\\Roms\\ROMS\\ROMS\\Zaxxon (1983) (Coleco) (2454) ~.bin to D:\\Anaconda3\\envs\\SKYNET\\lib\\site-packages\\atari_py\\atari_roms\\zaxxon.bin\n"
     ]
    }
   ],
   "source": [
    "import_roms.import_roms('.\\Roms\\ROMS\\ROMS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a19eaf31-ea2d-4141-91df-5604302ddf18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gym.wrappers.time_limit.TimeLimit"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENv=gym.make('Breakout-v0')\n",
    "type(ENv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "355ab012-f78f-4ba5-a7fa-c1d60ebf58fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class atari_env_wrapper():\n",
    "    \n",
    "    \"\"\" Wrapper Class to wrap around actual env and \n",
    "    return processed next state,done and reward info\n",
    "    so Qnet can ingest processed environment state to produce\n",
    "    actions. Example:\n",
    "    \n",
    "    In Atari games the Kframes argument sets the number of frames\n",
    "    to be used by the agent to produce an action.the agent repeats\n",
    "    the action chosen for kframes=4 consecutive atari frames\n",
    "    and concats the 4 produced observation into one tensor(frames) of\n",
    "    shape 4 by 84 by 84 -4 greyscale images of size 4 by 4.\n",
    "    \n",
    "    The reset() method resets the wrapped atari env and also executes\n",
    "    a random action kframes=4 times to produce the first video\"\"\"\n",
    "    \n",
    "   \n",
    "    def __init__(self,env,kframes=4):\n",
    "        self.env=env\n",
    "        self.kframes=kframes\n",
    "        self.action_space=self.env.action_space\n",
    "        \n",
    "        \n",
    "    def preproc(self,frames):\n",
    "        out=torch.tensor(np.transpose(frames,(0,3,1,2)))/255.\n",
    "        out=TF.rgb_to_grayscale(out)\n",
    "        out=out.squeeze()\n",
    "        out=TF.resize(out,(110,84))\n",
    "        out=TF.crop(out,top=110-84,left=0,height=84,width=84)\n",
    "        return out\n",
    "        \n",
    "    def step(self,action):\n",
    "        frames,rews,dones=[],0,[]\n",
    "        for i in range(self.kframes):\n",
    "            frame,rew,done,_=self.env.step(action)\n",
    "            frames.append(frame)\n",
    "            rews+=rew\n",
    "            dones.append(done)\n",
    "        return (self.preproc(np.stack(frames)),rews,any(dones))\n",
    "    \n",
    "    ## take 1 random step to produce k=4 frames for input to the Qnet\n",
    "    def reset(self):\n",
    "        self.env.reset()\n",
    "        init_act=self.env.action_space.sample()\n",
    "        return self.step(init_act)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "class Q_net(nn.Module):\n",
    "    \n",
    "    def __init__(self,n_actions=4,act=nn.ReLU(),kframes=4):\n",
    "        super(Q_net, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(kframes, 16, 8, 4),act)\n",
    "      \n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(16, 32, 4, 2),act)\n",
    "        self.pool1=nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1=nn.Sequential(nn.Linear(32,256),act)\n",
    "        self.fc2=nn.Linear(256,n_actions)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out=self.conv1(x)\n",
    "        out=self.conv2(out)\n",
    "        out=self.pool1(out)\n",
    "        out=out.squeeze()\n",
    "        out=self.fc1(out)\n",
    "        out=self.fc2(out)\n",
    "        return out\n",
    "        \n",
    "            \n",
    "                    \n",
    "\n",
    "class atari_DQN():\n",
    "    \"\"\" The Class implements DQN algorithm for atari games.Experiance is generated by acting epsilon greedily wrt the currently stored Q (action value) function\n",
    "         policy evaluation is done by minimizing bellman error from generated experiance,policy improvement is done by epsilon greedy sampling of actions.\n",
    "            \"\"\"\n",
    "    def __init__(self,Q_net_arch,optimizer,kframes,device=torch.device('cuda'),lr=0.001,training_begins=10000,buffer_size=100000,update_tgt_lag=1000,batch_size=32,\n",
    "                 env_wrapper=atari_env_wrapper(env=gym.make('Breakout-v0'),kframes=4),gamma=0.99,bellman_loss=nn.MSELoss(),eps_start=1.0,eps_end=0.1):\n",
    "       \n",
    "        self.batch_size=batch_size\n",
    "        self.buffer=self.replay_buffer(buffer_size)\n",
    "        self.env_wrapper=env_wrapper(env=gym.make('Breakout-v0'),kframes=kframes)\n",
    "        self.device=torch.device('cpu') if not torch.cuda.is_available() else device\n",
    "        print(f'using device:{self.device}')\n",
    "        self.Q_net=Q_net_arch(kframes=kframes).to(device)\n",
    "        self.Q_targ=copy.deepcopy(self.Q_net)\n",
    "        self.optimizer=optimizer(self.Q_net.parameters(),lr)\n",
    "        self.eps_start=eps_start\n",
    "        self.eps_end=eps_end\n",
    "        self.gamma=gamma\n",
    "        self.bellman_loss=bellman_loss.to(self.device)\n",
    "        self.update_tgt_lag=update_tgt_lag\n",
    "        self.training_begins=training_begins\n",
    "        self.rew_per_epi_log='reward_per_episode_log.csv'\n",
    "    \n",
    "    class replay_buffer():\n",
    "        def __init__(self,max_size):\n",
    "            self.max_size=max_size\n",
    "            self.items=[]\n",
    "            \n",
    "        def add_item(self,item):\n",
    "            self.items.append(item)\n",
    "            if len(self.items)>self.max_size:\n",
    "                self.items.pop(0)\n",
    "                \n",
    "        def sample_items(self,batch_size):\n",
    "            return random.sample(self.items,min(batch_size,len(self.items)))\n",
    "            \n",
    "            \n",
    "    def Q_net_forward(self,proc_frames_batch):\n",
    "        return self.Q_net(proc_frames_batch.to(self.device))\n",
    "    \n",
    "    def Q_targ_forward(self,proc_frames_batch):\n",
    "        return self.Q_targ(proc_frames_batch.to(self.device))\n",
    "        \n",
    "        \n",
    "    def select_action(self,proc_frames,eps):\n",
    "        ## act epsilon greedily wrt current Q function\n",
    "        if np.random.rand()<=eps:\n",
    "            return self.env_wrapper.action_space.sample()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                   return torch.argmax(self.Q_net_forward(proc_frames.unsqueeze(0)))\n",
    "                \n",
    "  \n",
    "        \n",
    "    def eval_agent(self,eps=0.05,epis=100):\n",
    "        all_rews=[]\n",
    "        for ep in range(epis):\n",
    "            _,epi_rew,done=self.env_wrapper.reset()\n",
    "            while not done:\n",
    "                action=self.select_action(frames,eps)\n",
    "                _,rew,done=self.env_wrapper.step(action)\n",
    "                epi_rew+=rew\n",
    "            all_rews.append(epi_rew)\n",
    "        all_rews=np.array(all_rews)\n",
    "        \n",
    "        return {'mean_rew_per_epi':all_rews.mean(),\n",
    "                'std_dev_rew':all_rews.std()} \n",
    "                \n",
    "                \n",
    "    def train(self,timesteps):\n",
    "        ## set up decay factor for random exploration-epsilon\n",
    "        eps_anneal_factor=np.exp(np.log(self.eps_end/self.eps_start)/(-self.training_begins+timesteps))\n",
    "        eps=self.eps_start\n",
    "        print(eps_anneal_factor)\n",
    "        epis,total_rew,episode_rew,epoch_t_minus1=0,0,0,0\n",
    "        proc_frames,rew,done=self.env_wrapper.reset()\n",
    "       \n",
    "        for t in tq(range(timesteps),position=0,leave=True):\n",
    "            proc_frames_t=proc_frames\n",
    "            a=self.select_action(proc_frames_t,eps)\n",
    "           \n",
    "            proc_frames,rew,done=self.env_wrapper.step(a)\n",
    "            total_rew+=rew\n",
    "            episode_rew+=rew\n",
    "            \n",
    "            if done:\n",
    "                with torch.no_grad():\n",
    "                    target=torch.tensor(rew).to(self.device)\n",
    "                    proc_frames,rew,done=self.env_wrapper.reset()\n",
    "                epis+=1\n",
    "                if epis%10==0:\n",
    "                    row={'episode':epis,'reward_per_episode':total_rew/epis,'reward_this_episode':episode_rew,'epsilon':eps}\n",
    "                    print(row)\n",
    "                    #df=pd.DataFrame(row)\n",
    "                    #df.to_csv(self.rew_per_epi_log, mode='a', header=not os.path.exists(self.rew_per_epi_log))\n",
    "                episode_rew=0    \n",
    "                \n",
    "            else:\n",
    "                proc_frames_t_plus1=proc_frames\n",
    "                a_prime=self.select_action(proc_frames_t_plus1,eps)\n",
    "                with torch.no_grad():\n",
    "                    ## need an extra leading dim to do forwarf pass for 1 sample minibatch\n",
    "                    target=rew+self.gamma*self.Q_targ_forward(proc_frames_t_plus1.unsqueeze(0))[a_prime]\n",
    "                \n",
    "            ## add the tuple of Q_input and taget to replay buffer    \n",
    "            self.buffer.add_item((proc_frames_t,a,target))\n",
    "            if t>self.training_begins:\n",
    "                train_steps=t-self.training_begins\n",
    "                if train_steps==0:\n",
    "                    print('training_begins')\n",
    "                batch=self.buffer.sample_items(self.batch_size)\n",
    "                x_b,a_b,y_b=zip(*batch)\n",
    "                #calculating q(x,a) for all actions\n",
    "                out_b=self.Q_net_forward(torch.stack(x_b))\n",
    "                #calculating q(x,a) for the action selected\n",
    "                out_b=torch.stack([out[a] for out,a in zip(out_b,a_b)])\n",
    "                #calculating bellman error for minibatch and do backward step\n",
    "                bellman_loss=self.bellman_loss(out_b,torch.stack(y_b))\n",
    "                self.optimizer.zero_grad()\n",
    "                bellman_loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                ## decay epsilon exploration\n",
    "                eps=eps*eps_anneal_factor\n",
    "                \n",
    "                ## printing loss statistics every n=50 epochs\n",
    "                epoch_t=(train_steps*self.batch_size)//self.buffer.max_size\n",
    "                if epoch_t-epoch_t_minus1==1 and epoch_t%100==0:\n",
    "                    print ({'epoch':epoch_t,'bellman_loss':bellman_loss.detach().item()})\n",
    "                epoch_t_minus1=epoch_t\n",
    "                \n",
    "                ## update the target Q network with a lagged copy of the Q  network\n",
    "                if t%self.update_tgt_lag==0:\n",
    "                    self.Q_targ=copy.deepcopy(self.Q_net)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f566997a-85e3-46ae-a9c3-a02440c38149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.core import Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eef97e-e5fd-409c-8a74-8e6d8787bcfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df89e8fc-4dc0-47eb-b6fa-a25340b837a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d03f4da-2738-4f00-a586-cfffb2d477de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device:cuda\n"
     ]
    }
   ],
   "source": [
    "dqn=atari_DQN(Q_net,RMSprop,training_begins=500,buffer_size=1000,lr=0.0001,update_tgt_lag=1000,eps_start=0.3,eps_end=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c943b3e4-85b9-42f2-8e0c-9362a598e59c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999819925292799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                         | 1204/100000 [00:37<1:02:25, 26.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 10, 'reward_per_episode': 1.8, 'reward_this_episode': 2.0, 'epsilon': 0.29625280090086076}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▍                                                                        | 2022/100000 [01:06<1:04:13, 25.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 20, 'reward_per_episode': 1.8, 'reward_this_episode': 2.0, 'epsilon': 0.2919209081988211}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▎                                                                       | 3080/100000 [01:45<1:07:58, 23.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 30, 'reward_per_episode': 1.9666666666666666, 'reward_this_episode': 5.0, 'epsilon': 0.28641701273108194}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▊                                                                         | 3631/100000 [02:05<56:48, 28.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 100, 'bellman_loss': 0.0007708743796683848}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▉                                                                       | 3939/100000 [02:16<1:02:51, 25.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 40, 'reward_per_episode': 1.925, 'reward_this_episode': 1.0, 'epsilon': 0.28201048847684423}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▌                                                                      | 4810/100000 [02:50<1:06:15, 23.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 50, 'reward_per_episode': 1.84, 'reward_this_episode': 3.0, 'epsilon': 0.2776267603221416}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▏                                                                     | 5620/100000 [03:20<1:02:44, 25.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 60, 'reward_per_episode': 1.85, 'reward_this_episode': 1.0, 'epsilon': 0.27360170914253756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▋                                                                     | 6325/100000 [03:47<1:05:22, 23.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 70, 'reward_per_episode': 1.7428571428571429, 'reward_this_episode': 1.0, 'epsilon': 0.27015505152096714}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|████▉                                                                     | 6752/100000 [04:04<1:14:19, 20.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 200, 'bellman_loss': 0.0008057102095335722}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▏                                                                    | 7088/100000 [04:16<1:09:43, 22.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 80, 'reward_per_episode': 1.6125, 'reward_this_episode': 2.0, 'epsilon': 0.2664637541892154}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████                                                                    | 8198/100000 [05:02<1:03:57, 23.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 90, 'reward_per_episode': 1.6222222222222222, 'reward_this_episode': 2.0, 'epsilon': 0.2611951326672595}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████▉                                                                   | 9407/100000 [05:46<1:09:20, 21.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 100, 'reward_per_episode': 1.57, 'reward_this_episode': 2.0, 'epsilon': 0.25556084426943076}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▌                                                                    | 9882/100000 [06:04<56:07, 26.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 300, 'bellman_loss': 1.7716543879942037e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|███████▋                                                                 | 10501/100000 [06:26<1:03:00, 23.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 110, 'reward_per_episode': 1.518181818181818, 'reward_this_episode': 2.0, 'epsilon': 0.25058449881274}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████████▌                                                                | 11644/100000 [07:09<1:04:20, 22.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 120, 'reward_per_episode': 1.55, 'reward_this_episode': 3.0, 'epsilon': 0.2454795047148731}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████████▏                                                               | 12663/100000 [07:47<1:05:20, 22.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 130, 'reward_per_episode': 1.5615384615384615, 'reward_this_episode': 1.0, 'epsilon': 0.2410117468420766}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████████▊                                                                 | 13004/100000 [08:00<52:22, 27.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 400, 'bellman_loss': 0.00013647688319906592}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████▏                                                              | 13924/100000 [08:34<1:01:36, 23.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 140, 'reward_per_episode': 1.5642857142857143, 'reward_this_episode': 2.0, 'epsilon': 0.23560485463735065}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████                                                                | 14777/100000 [09:05<55:47, 25.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 150, 'reward_per_episode': 1.6, 'reward_this_episode': 1.0, 'epsilon': 0.23200931889891044}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████                                                               | 16131/100000 [09:56<50:57, 27.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 500, 'bellman_loss': 0.00020087524899281561}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▏                                                              | 16176/100000 [09:58<58:38, 23.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 160, 'reward_per_episode': 1.5875, 'reward_this_episode': 2.0, 'epsilon': 0.22624146719053403}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████▍                                                            | 17068/100000 [10:32<1:20:44, 17.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 170, 'reward_per_episode': 1.5823529411764705, 'reward_this_episode': 3.0, 'epsilon': 0.2226284067251499}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████▎                                                             | 17751/100000 [11:01<59:28, 23.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 180, 'reward_per_episode': 1.5666666666666667, 'reward_this_episode': 1.0, 'epsilon': 0.21991098226740768}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████                                                             | 18753/100000 [11:40<58:21, 23.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 190, 'reward_per_episode': 1.568421052631579, 'reward_this_episode': 0.0, 'epsilon': 0.21597468087813104}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████▍                                                            | 19256/100000 [12:01<53:07, 25.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 600, 'bellman_loss': 0.02626863494515419}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████▌                                                            | 19394/100000 [12:06<51:11, 26.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 200, 'reward_per_episode': 1.55, 'reward_this_episode': 2.0, 'epsilon': 0.21350373043114354}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▏                                                           | 20196/100000 [12:36<54:52, 24.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 210, 'reward_per_episode': 1.561904761904762, 'reward_this_episode': 1.0, 'epsilon': 0.21044623216360367}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████▊                                                           | 21016/100000 [13:06<55:10, 23.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 220, 'reward_per_episode': 1.5818181818181818, 'reward_this_episode': 1.0, 'epsilon': 0.20736155919485358}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████▎                                                          | 21784/100000 [13:35<54:14, 24.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 230, 'reward_per_episode': 1.5782608695652174, 'reward_this_episode': 1.0, 'epsilon': 0.20451351685052102}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████▊                                                          | 22380/100000 [13:57<45:40, 28.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 700, 'bellman_loss': 0.05355031415820122}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████▉                                                          | 22510/100000 [14:02<54:07, 23.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 240, 'reward_per_episode': 1.5625, 'reward_this_episode': 2.0, 'epsilon': 0.20185720246234107}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████████▎                                                         | 23086/100000 [14:24<59:04, 21.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 250, 'reward_per_episode': 1.548, 'reward_this_episode': 2.0, 'epsilon': 0.19975989130760002}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████▊                                                         | 23803/100000 [14:58<55:09, 23.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 260, 'reward_per_episode': 1.5346153846153847, 'reward_this_episode': 2.0, 'epsilon': 0.19721148081753104}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████▍                                                        | 24566/100000 [15:27<49:33, 25.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 270, 'reward_per_episode': 1.5222222222222221, 'reward_this_episode': 1.0, 'epsilon': 0.19452035990601432}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████                                                        | 25464/100000 [16:00<55:58, 22.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 280, 'reward_per_episode': 1.5357142857142858, 'reward_this_episode': 3.0, 'epsilon': 0.19139664953466534}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████▏                                                       | 25505/100000 [16:02<44:19, 28.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 800, 'bellman_loss': 0.006051598582416773}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████▊                                                       | 26478/100000 [16:38<53:22, 22.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 290, 'reward_per_episode': 1.5275862068965518, 'reward_this_episode': 1.0, 'epsilon': 0.18793351076008102}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████▊                                                      | 27669/100000 [17:21<50:07, 24.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 300, 'reward_per_episode': 1.54, 'reward_this_episode': 1.0, 'epsilon': 0.1839424865666481}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████▎                                                     | 28417/100000 [17:49<50:28, 23.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 310, 'reward_per_episode': 1.5419354838709678, 'reward_this_episode': 1.0, 'epsilon': 0.18148798290615986}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████▍                                                     | 28629/100000 [17:57<43:33, 27.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 900, 'bellman_loss': 0.0008465307764708996}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████▊                                                     | 29113/100000 [18:15<53:26, 22.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 320, 'reward_per_episode': 1.53125, 'reward_this_episode': 0.0, 'epsilon': 0.17921785023435116}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████▍                                                    | 29992/100000 [18:48<49:44, 23.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 330, 'reward_per_episode': 1.5212121212121212, 'reward_this_episode': 0.0, 'epsilon': 0.17641292641427958}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████████████████▍                                                   | 31276/100000 [19:42<54:47, 20.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 340, 'reward_per_episode': 1.5176470588235293, 'reward_this_episode': 2.0, 'epsilon': 0.17237142502793518}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████████████▊                                                   | 31755/100000 [20:01<44:23, 25.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1000, 'bellman_loss': 0.0018535091076046228}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████████████▋                                                 | 32440/100000 [20:29<1:06:51, 16.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 350, 'reward_per_episode': 1.5371428571428571, 'reward_this_episode': 5.0, 'epsilon': 0.16879597072239916}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████▏                                                 | 33621/100000 [21:17<50:32, 21.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 360, 'reward_per_episode': 1.525, 'reward_this_episode': 1.0, 'epsilon': 0.16524408723168107}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████▉                                                 | 34648/100000 [21:58<54:36, 19.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 370, 'reward_per_episode': 1.527027027027027, 'reward_this_episode': 0.0, 'epsilon': 0.16221909601410742}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████▏                                                | 34880/100000 [22:07<39:46, 27.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1100, 'bellman_loss': 0.0051562893204391}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████▌                                                | 35456/100000 [22:30<45:50, 23.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 380, 'reward_per_episode': 1.5236842105263158, 'reward_this_episode': 2.0, 'epsilon': 0.15987874854039044}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████▎                                               | 36409/100000 [23:08<50:19, 21.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 390, 'reward_per_episode': 1.5205128205128204, 'reward_this_episode': 0.0, 'epsilon': 0.15715277430308391}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████████▎                                              | 37711/100000 [23:58<43:10, 24.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 400, 'reward_per_episode': 1.505, 'reward_this_episode': 0.0, 'epsilon': 0.15351380327421663}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████████▌                                              | 38004/100000 [24:09<38:03, 27.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1200, 'bellman_loss': 0.008902966976165771}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|█████████████████████████████▏                                             | 38985/100000 [24:50<46:42, 21.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 410, 'reward_per_episode': 1.5048780487804878, 'reward_this_episode': 0.0, 'epsilon': 0.1500347253997268}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████▊                                             | 39756/100000 [25:19<41:28, 24.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 420, 'reward_per_episode': 1.5047619047619047, 'reward_this_episode': 0.0, 'epsilon': 0.14796605436177374}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|██████████████████████████████▋                                            | 40945/100000 [26:04<41:18, 23.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 430, 'reward_per_episode': 1.4930232558139536, 'reward_this_episode': 1.0, 'epsilon': 0.1448316175800898}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|██████████████████████████████▊                                            | 41130/100000 [26:11<35:06, 27.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1300, 'bellman_loss': 0.0029242122545838356}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|███████████████████████████████▉                                           | 42524/100000 [27:03<40:12, 23.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 440, 'reward_per_episode': 1.5068181818181818, 'reward_this_episode': 3.0, 'epsilon': 0.1407739996256151}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████                                          | 44043/100000 [28:00<39:11, 23.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 450, 'reward_per_episode': 1.5044444444444445, 'reward_this_episode': 0.0, 'epsilon': 0.1369705796035339}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████▏                                         | 44254/100000 [28:08<35:00, 26.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1400, 'bellman_loss': 0.012977592647075653}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████▍                                         | 44656/100000 [28:24<39:31, 23.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 460, 'reward_per_episode': 1.5043478260869565, 'reward_this_episode': 3.0, 'epsilon': 0.13547179879332177}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████████████████████▎                                        | 45710/100000 [29:04<38:30, 23.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 470, 'reward_per_episode': 1.5, 'reward_this_episode': 2.0, 'epsilon': 0.13292239198626718}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|███████████████████████████████████▌                                       | 47377/100000 [30:08<41:41, 21.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1500, 'bellman_loss': 0.014484289102256298}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|███████████████████████████████████▋                                       | 47619/100000 [30:18<39:43, 21.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 480, 'reward_per_episode': 1.5229166666666667, 'reward_this_episode': 2.0, 'epsilon': 0.1284259986708275}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████████████████████████████████████▋                                      | 48848/100000 [31:06<35:06, 24.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 490, 'reward_per_episode': 1.5224489795918368, 'reward_this_episode': 1.0, 'epsilon': 0.12561723669754826}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████▎                                     | 49781/100000 [31:42<37:26, 22.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 500, 'reward_per_episode': 1.526, 'reward_this_episode': 2.0, 'epsilon': 0.12352435684212522}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████████████████████████████████████▉                                     | 50504/100000 [32:10<33:41, 24.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1600, 'bellman_loss': 0.005608578212559223}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|██████████████████████████████████████                                     | 50722/100000 [32:18<36:02, 22.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 510, 'reward_per_episode': 1.511764705882353, 'reward_this_episode': 2.0, 'epsilon': 0.12145103569149507}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|███████████████████████████████████████▏                                   | 52188/100000 [33:13<34:07, 23.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 520, 'reward_per_episode': 1.5115384615384615, 'reward_this_episode': 2.0, 'epsilon': 0.11828677744643544}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|████████████████████████████████████████                                   | 53454/100000 [34:01<34:06, 22.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 530, 'reward_per_episode': 1.5075471698113208, 'reward_this_episode': 1.0, 'epsilon': 0.11562062186529298}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████████████████████████████▏                                  | 53631/100000 [34:07<28:07, 27.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1700, 'bellman_loss': 0.010449016466736794}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████████████████████████████▉                                  | 54568/100000 [34:47<47:04, 16.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 540, 'reward_per_episode': 1.512962962962963, 'reward_this_episode': 1.0, 'epsilon': 0.11332024215791815}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████████████████████████████████████████▋                                 | 55618/100000 [35:30<28:25, 26.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 550, 'reward_per_episode': 1.5036363636363637, 'reward_this_episode': 1.0, 'epsilon': 0.11120171592362459}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████████████████████▍                                | 56507/100000 [36:06<37:35, 19.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 560, 'reward_per_episode': 1.5142857142857142, 'reward_this_episode': 3.0, 'epsilon': 0.10943174392974048}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████████████████████▌                                | 56755/100000 [36:17<27:13, 26.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1800, 'bellman_loss': 0.009670205414295197}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|███████████████████████████████████████████                                | 57396/100000 [36:39<27:56, 25.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 570, 'reward_per_episode': 1.5263157894736843, 'reward_this_episode': 1.0, 'epsilon': 0.10769382272252506}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|███████████████████████████████████████████▋                               | 58244/100000 [37:08<24:48, 28.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 580, 'reward_per_episode': 1.5379310344827586, 'reward_this_episode': 2.0, 'epsilon': 0.10606559980559516}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|████████████████████████████████████████████▏                              | 58905/100000 [37:32<26:16, 26.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 590, 'reward_per_episode': 1.540677966101695, 'reward_this_episode': 1.0, 'epsilon': 0.10481246766694001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████▊                              | 59808/100000 [38:03<26:04, 25.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 600, 'reward_per_episode': 1.56, 'reward_this_episode': 5.0, 'epsilon': 0.10312190567502301}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████▉                              | 59880/100000 [38:05<22:51, 29.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1900, 'bellman_loss': 0.009191923774778843}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████████████████████████████████▍                             | 60660/100000 [38:32<24:17, 26.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 610, 'reward_per_episode': 1.5688524590163935, 'reward_this_episode': 2.0, 'epsilon': 0.10155183273091671}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████████████████████████████████████████████                             | 61450/100000 [39:00<23:41, 27.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 620, 'reward_per_episode': 1.5774193548387097, 'reward_this_episode': 0.0, 'epsilon': 0.10011918367970782}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████▋                            | 62204/100000 [39:26<22:33, 27.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 630, 'reward_per_episode': 1.5793650793650793, 'reward_this_episode': 2.0, 'epsilon': 0.09876541991925201}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|███████████████████████████████████████████████▎                           | 63005/100000 [39:53<22:57, 26.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 2000, 'bellman_loss': 0.001813520910218358}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|███████████████████████████████████████████████▎                           | 63118/100000 [39:58<26:25, 23.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 640, 'reward_per_episode': 1.584375, 'reward_this_episode': 1.0, 'epsilon': 0.09714964784664475}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████▊                           | 63747/100000 [40:20<23:08, 26.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 650, 'reward_per_episode': 1.5876923076923077, 'reward_this_episode': 1.0, 'epsilon': 0.09606065095956366}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████████████████████████▎                          | 64491/100000 [40:47<29:37, 19.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 660, 'reward_per_episode': 1.606060606060606, 'reward_this_episode': 2.0, 'epsilon': 0.09477712389940798}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████████████████████████▊                          | 65154/100000 [41:11<21:55, 26.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 670, 'reward_per_episode': 1.6119402985074627, 'reward_this_episode': 2.0, 'epsilon': 0.09365567506741422}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████████▌                         | 66023/100000 [41:41<26:52, 21.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 680, 'reward_per_episode': 1.6205882352941177, 'reward_this_episode': 0.0, 'epsilon': 0.09220149938981535}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████████▌                         | 66129/100000 [41:45<18:58, 29.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 2100, 'bellman_loss': 0.0054150596261024475}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████████████████████████                         | 66700/100000 [42:05<22:11, 25.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 690, 'reward_per_episode': 1.6318840579710145, 'reward_this_episode': 2.0, 'epsilon': 0.09108427941721484}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████████████████████████▍                        | 67313/100000 [42:26<21:11, 25.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 700, 'reward_per_episode': 1.6342857142857143, 'reward_this_episode': 3.0, 'epsilon': 0.09008273616602333}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████████████████████████████████████████████████▉                        | 67919/100000 [42:47<24:00, 22.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 710, 'reward_per_episode': 1.6366197183098592, 'reward_this_episode': 1.0, 'epsilon': 0.08910664589785958}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████████████████████████████████▉                       | 69257/100000 [43:33<16:18, 31.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 2200, 'bellman_loss': 0.016231663525104523}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████▏                      | 69531/100000 [43:42<18:57, 26.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 720, 'reward_per_episode': 1.6347222222222222, 'reward_this_episode': 1.0, 'epsilon': 0.08655409562939807}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|████████████████████████████████████████████████████▉                      | 70518/100000 [44:15<18:02, 27.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 730, 'reward_per_episode': 1.63013698630137, 'reward_this_episode': 1.0, 'epsilon': 0.08503390767214809}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|█████████████████████████████████████████████████████▍                     | 71276/100000 [44:48<22:23, 21.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 740, 'reward_per_episode': 1.6391891891891892, 'reward_this_episode': 0.0, 'epsilon': 0.08387807780535035}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████████████████████████████▉                     | 71905/100000 [45:11<17:23, 26.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 750, 'reward_per_episode': 1.644, 'reward_this_episode': 1.0, 'epsilon': 0.0829348613222155}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████████████████████████████████▎                    | 72380/100000 [45:27<14:17, 32.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 2300, 'bellman_loss': 0.03089515119791031}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████████████▋                    | 72845/100000 [45:43<17:02, 26.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 760, 'reward_per_episode': 1.6657894736842105, 'reward_this_episode': 5.0, 'epsilon': 0.08154429170069769}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████▏                   | 73548/100000 [46:07<17:14, 25.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 770, 'reward_per_episode': 1.6727272727272726, 'reward_this_episode': 3.0, 'epsilon': 0.08051704938058747}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████▋                   | 74287/100000 [46:34<15:32, 27.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 780, 'reward_per_episode': 1.6833333333333333, 'reward_this_episode': 3.0, 'epsilon': 0.07945265541300839}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████▏                  | 74990/100000 [46:59<16:51, 24.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 790, 'reward_per_episode': 1.6962025316455696, 'reward_this_episode': 3.0, 'epsilon': 0.07845458768787317}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|████████████████████████████████████████████████████████▋                  | 75506/100000 [47:17<14:55, 27.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 2400, 'bellman_loss': 0.005732540972530842}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|████████████████████████████████████████████████████████▋                  | 75622/100000 [47:21<16:22, 24.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 800, 'reward_per_episode': 1.69375, 'reward_this_episode': 1.0, 'epsilon': 0.07756537467757442}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|█████████████████████████████████████████████████████████▌                 | 76739/100000 [48:00<14:20, 27.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 810, 'reward_per_episode': 1.7061728395061728, 'reward_this_episode': 1.0, 'epsilon': 0.0760194015659101}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|██████████████████████████████████████████████████████████                 | 77469/100000 [48:25<15:14, 24.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 820, 'reward_per_episode': 1.7134146341463414, 'reward_this_episode': 2.0, 'epsilon': 0.07502662267004374}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████████████████████████████████████████████████▊                | 78452/100000 [48:59<12:48, 28.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 830, 'reward_per_episode': 1.716867469879518, 'reward_this_episode': 3.0, 'epsilon': 0.07371155152465324}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████▉                | 78627/100000 [49:05<12:12, 29.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 2500, 'bellman_loss': 0.02565350942313671}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████████▎               | 79113/100000 [49:22<12:30, 27.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 840, 'reward_per_episode': 1.7226190476190477, 'reward_this_episode': 3.0, 'epsilon': 0.07283804909472162}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████████████████████████████████████████████████████████▍              | 80557/100000 [50:11<12:26, 26.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 850, 'reward_per_episode': 1.728235294117647, 'reward_this_episode': 3.0, 'epsilon': 0.07096973062099916}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████████████████████████████████████████████████████████▉              | 81256/100000 [50:36<12:10, 25.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 860, 'reward_per_episode': 1.7348837209302326, 'reward_this_episode': 4.0, 'epsilon': 0.0700820095630408}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████▎             | 81755/100000 [50:54<10:16, 29.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 2600, 'bellman_loss': 0.0026283462066203356}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████▌             | 82064/100000 [51:05<10:58, 27.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 870, 'reward_per_episode': 1.7367816091954023, 'reward_this_episode': 0.0, 'epsilon': 0.06906844341505246}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████████████████████████████             | 82787/100000 [51:30<13:28, 21.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 880, 'reward_per_episode': 1.7477272727272728, 'reward_this_episode': 2.0, 'epsilon': 0.06817380637445752}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████████████████████████████▌            | 83439/100000 [51:53<11:06, 24.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 890, 'reward_per_episode': 1.7516853932584269, 'reward_this_episode': 2.0, 'epsilon': 0.06737927319954888}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████████            | 84118/100000 [52:17<09:28, 27.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 900, 'reward_per_episode': 1.7544444444444445, 'reward_this_episode': 4.0, 'epsilon': 0.06656402666939432}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████████████████████████████████████▋           | 84879/100000 [52:43<08:16, 30.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 2700, 'bellman_loss': 0.0015911058289930224}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████████████████████████████████████▉           | 85196/100000 [52:54<11:04, 22.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 910, 'reward_per_episode': 1.7626373626373626, 'reward_this_episode': 2.0, 'epsilon': 0.06528080489072534}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████▌          | 86006/100000 [53:23<09:00, 25.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 920, 'reward_per_episode': 1.7728260869565218, 'reward_this_episode': 3.0, 'epsilon': 0.06433667651365377}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|█████████████████████████████████████████████████████████████████▏         | 86984/100000 [53:57<07:50, 27.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 930, 'reward_per_episode': 1.7774193548387096, 'reward_this_episode': 2.0, 'epsilon': 0.06321467086281317}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|█████████████████████████████████████████████████████████████████▋         | 87649/100000 [54:19<08:13, 25.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 940, 'reward_per_episode': 1.7797872340425531, 'reward_this_episode': 0.0, 'epsilon': 0.06246218491491233}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████         | 88003/100000 [54:33<08:22, 23.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 2800, 'bellman_loss': 0.006149732042104006}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████▎        | 88455/100000 [54:51<07:12, 26.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 950, 'reward_per_episode': 1.7905263157894737, 'reward_this_episode': 4.0, 'epsilon': 0.06156103813096215}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|██████████████████████████████████████████████████████████████████▉        | 89271/100000 [55:19<06:39, 26.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 960, 'reward_per_episode': 1.8052083333333333, 'reward_this_episode': 3.0, 'epsilon': 0.06066305988179089}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████████▍       | 89888/100000 [55:41<06:27, 26.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 970, 'reward_per_episode': 1.8072164948453608, 'reward_this_episode': 2.0, 'epsilon': 0.05999170046302666}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|███████████████████████████████████████████████████████████████████▉       | 90567/100000 [56:04<06:12, 25.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 980, 'reward_per_episode': 1.813265306122449, 'reward_this_episode': 3.0, 'epsilon': 0.0592637044474676}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|████████████████████████████████████████████████████████████████████▎      | 91131/100000 [56:23<04:50, 30.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 2900, 'bellman_loss': 0.009663557633757591}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|████████████████████████████████████████████████████████████████████▋      | 91666/100000 [56:42<05:10, 26.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 990, 'reward_per_episode': 1.8151515151515152, 'reward_this_episode': 2.0, 'epsilon': 0.05810133584830086}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████████████████████████████████████████████████████████████████▋     | 92848/100000 [57:23<04:30, 26.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 1000, 'reward_per_episode': 1.82, 'reward_this_episode': 2.0, 'epsilon': 0.056877716216447556}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|██████████████████████████████████████████████████████████████████████▋    | 94254/100000 [58:11<03:25, 27.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 3000, 'bellman_loss': 0.006983501836657524}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|██████████████████████████████████████████████████████████████████████▋    | 94281/100000 [58:12<03:42, 25.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 1010, 'reward_per_episode': 1.8316831683168318, 'reward_this_episode': 2.0, 'epsilon': 0.055429763874260705}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|███████████████████████████████████████████████████████████████████████▏   | 94901/100000 [58:34<03:06, 27.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 1020, 'reward_per_episode': 1.8333333333333333, 'reward_this_episode': 1.0, 'epsilon': 0.05481533435428074}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|███████████████████████████████████████████████████████████████████████▋   | 95506/100000 [58:55<02:51, 26.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 1030, 'reward_per_episode': 1.833009708737864, 'reward_this_episode': 2.0, 'epsilon': 0.05421943077861834}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|████████████████████████████████████████████████████████████████████████▏  | 96234/100000 [59:20<02:21, 26.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 1040, 'reward_per_episode': 1.835576923076923, 'reward_this_episode': 3.0, 'epsilon': 0.05351327687117409}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|████████████████████████████████████████████████████████████████████████▊  | 97106/100000 [59:50<01:50, 26.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 1050, 'reward_per_episode': 1.8485714285714285, 'reward_this_episode': 1.0, 'epsilon': 0.05267859075359098}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████  | 97378/100000 [1:00:00<01:35, 27.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 3100, 'bellman_loss': 0.014689910225570202}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|███████████████████████████████████████████████████████████████████████▍ | 97914/100000 [1:00:20<01:20, 25.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 1060, 'reward_per_episode': 1.849056603773585, 'reward_this_episode': 1.0, 'epsilon': 0.05191859264104831}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|████████████████████████████████████████████████████████████████████████▏| 98823/100000 [1:00:52<00:48, 24.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 1070, 'reward_per_episode': 1.8514018691588785, 'reward_this_episode': 1.0, 'epsilon': 0.05107565819555538}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████▋| 99523/100000 [1:01:16<00:19, 24.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 1080, 'reward_per_episode': 1.8555555555555556, 'reward_this_episode': 3.0, 'epsilon': 0.05043587283355551}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 100000/100000 [1:01:32<00:00, 27.08it/s]\n"
     ]
    }
   ],
   "source": [
    "dqn.train(100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dbbc32b7-d880-4f4d-ac5e-aab06f7b5174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2e8e26cd3a0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAARNklEQVR4nO3dXYxcd33G8e8zs+O1YydZrxOM402wKZEjWjUOWJAoqKIJaUOKQi9QRIRaWkVKL2gbChIk7RVSL0JVAbmgVC6B0pZCILxFURSaGlCF1Jq8AiFOsOM48bp27PgldtZe7+7MrxfnbLqYfTm7Z17O7P/5SNbOOXP2zP9o/Ow585+Z308RgZktf7VeD8DMusNhN0uEw26WCIfdLBEOu1kiHHazRJQKu6QbJT0naY+kO9s1KDNrPy31fXZJdeCXwA3AKPAocGtEPNO+4ZlZuwyU+N13AHsiYi+ApK8D7wfmDPvwcC0uHanPu9MzUWf/KxfTODRWYmhmy8vkG1dz2UVHWKnmvNvtH21y7FhLs91XJuwbgf0zlkeBd873C5eO1HnooYvm3ekzkxdyxz/9GRv/bie05j8wsyTU6oze9k4+f9s/sqVxct5Nb7rplbl30+5xnUvS7ZIek/TY0WOtTj+cmc2hTNgPAJfOWB7J1/2KiNgeEdsiYtu6YU/+m/VKmfQ9ClwuabOkFcAHgQfaMywza7clv2aPiClJfw58H6gDX4qIX7RtZGbWVmUm6IiIh4CH2jQWM+sgv4g2S4TDbpaIUpfxndJcAfXhIWj6rTozBgZoDkJN5fJQubCvq51m1bajvPCRLeCKWWYgOP/trzBUGy+1m8qF/fzaJH/8Gzv5n3Vv7vVQzCrj6qG9rNZUqX1ULuwAdYKBkpcsZstJY4HPxBfhCTqzRDjsZolw2M0S4bCbJaKSE3SDtUlWD5ylFf5bZFZTi4aapc/MlQt7Q7CxcYyzqxu9HopZZVzWOEp91vozxVUu7ABDtdNc0jje62GYVcb5tTOl9+HrZLNEOOxmiXDYzRLhsJslYsGwS/qSpMOSnp6xbljSI5J25z/XdnaYZlZWkTP7PwM3nrPuTmBHRFwO7MiXzazCFnzrLSL+S9Kmc1a/H3h3fvsrwI+AT7ZrUHWCRsmv85ktJ/U2FHdY6mv29RFxML99CFhfeiTnqPsrrmZAloWyVWqgDRN0kXWGnPPPjjvCmFXDUsP+sqQNAPnPw3Nt6I4wZtWw1PQ9AHw4v/1h4HvtGY6ZdUqRt96+Bvw3sEXSqKTbgLuBGyTtBt6TL5tZhRWZjb91jruub/NYXteOyQgz+1WV+9ZbDThfk6yov0qTkt/pM1sG6gSDy/H77HXgjXVoaN5JfrOkTAaMl4xD5cIOUJMYlItXmE1rMlH63FfJsNcRNV/Cm72u3oY8VDLsNWrU5ffkzabV2lCP0YkyS4TDbpaISoa9hd9nN5upHZmo3Gv2JnCsNcWR5mu9HopZZdSVnZnrJfZRubADHGs2ONFa5Q/VmJF9qGaodoaL6pOl9lO5sLeACWqMxYpeD8WsMs7jLC2W4Zn9VGslhyaHej0Ms8pYqUneWD9bah+VDPt4NDjdGuz1MMwqYzLKR7WSs/Fm1n4Ou1kiKncZ3wxoRo3JKDMVYba8TLQhD5ULO8CRqQvYN76u18Mwq4zhgddoxmEaJd6NXjDski4F/oWsXHQA2yPiHknDwH3AJmAfcEtElO6z3CKbjX/l7JqyuzJbNk6tWlX6M3RFzuxTwMcj4glJ5wOPS3oE+BOyrjB3S7qTrCtM6UYRTcTxqdUcGV9DK/yhGrOagmNTq0vvp0gNuoPAwfz2KUm7gI10qCtMM8QLp9fx4uFhwmE3QwouW32ciQtrnFeiPuOiXrPnbaCuAnZSsCuMpNuB2wE2blx48r+FGG82mJqog8NuBgrONMtXbir81pukNcC3gI9GxMmZ983XFcZNIsyqoVD6JDXIgv7ViPh2vrpwVxgz670is/EC7gV2RcRnZtw13RXmbtrcFaYVIlryZbwZgGCqDWWpirxmvxb4I+Dnkp7K1/01Wci/kXeIeRG4pfRocuPNBpytu5K0GYCyTLRKfuW7yGz8j7OHm1Xbu8I0EZPNOpqSw24G2Zm91Z0ze1eNR509By9m+MkactjNiBr8cvgNjG+qk9VyWprKhf1UayWDz63iDd99Fianej0cs95rDDA2cgVjV68AJpa8m8qFHaA2Cc3jr0Jr6X/FzJaNWp3aBLRKTtL5jW+zRDjsZolw2M0S4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRDjsZolw2M0S4bCbJcJhN0uEw26WiAXDLmmlpJ9I+qmkX0j6VL5+s6SdkvZIuk/Sis4P18yWqsiZ/SxwXURcCWwFbpR0NfBp4LMR8RbgOHBbx0ZpZqUtGPbIvJYvNvJ/AVwH3J+v/wrwh50YoJm1R9G68fW8suxh4BHgeeBEREzXjRolawk12+/eLukxSY8dPVa2NZ2ZLVWhsEdEMyK2AiPAO4Arij6AO8KYVcOi0hcRJ4AfAtcAQ5Kma9iNAAfaOzQza6cis/EXSxrKb68CbgB2kYX+A/lmbe0IY2btV6S67AbgK5LqZH8cvhERD0p6Bvi6pL8FniRrEWVmFVWkI8zPyNo0n7t+L9nrdzPrA54xM0uEw26WCIfdLBEOu1kiHHazRDjsZolw2M0S4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRDjsZolw2M0S4bCbJcJhN0tE4bDn5aSflPRgvuyOMGZ9ZDFn9jvICk1Oc0cYsz5StEnECPAHwBfzZeGOMGZ9peiZ/XPAJ4Dpli7rcEcYs75SpG78+4DDEfH4Uh7AHWHMqqFI3fhrgZsl3QSsBC4A7iHvCJOf3d0RxqziinRxvSsiRiJiE/BB4AcR8SHcEcasr5S5rv4k8DFJe8hew7sjjFmFFbmMf11E/Aj4UX7bHWHM+ohnzMwS4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRDjsZolw2M0S4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRDjsZolw2M0SUahSjaR9wCmgCUxFxDZJw8B9wCZgH3BLRBzvzDDNrKzFnNl/NyK2RsS2fPlOYEdEXA7syJfNrKLKXMa/n6wTDLgjjFnlFQ17AP8h6XFJt+fr1kfEwfz2IWD9bL/ojjBm1VC0uuy7IuKApDcAj0h6duadERGSYrZfjIjtwHaAK3+7Mes2ZtZ5hc7sEXEg/3kY+A5ZCemXJW0AyH8e7tQgzay8Ir3eVks6f/o28HvA08ADZJ1gwB1hzCqvyGX8euA7WZdmBoB/j4iHJT0KfEPSbcCLwC2dG6aZlbVg2PPOL1fOsv4ocH0nBmVm7edP0JklwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslolDYJQ1Jul/Ss5J2SbpG0rCkRyTtzn+u7fRgzWzpip7Z7wEejogryEpU7cIdYcz6SpHqshcCvwPcCxARExFxAneEMesrRc7sm4EjwJclPSnpi3lJaXeEMesjRcI+ALwN+EJEXAWMcc4le0QEWYuoXxMR2yNiW0RsWzfs+UCzXimSvlFgNCJ25sv3k4XfHWHM+siCYY+IQ8B+SVvyVdcDz+COMGZ9pWhjx78AvippBbAX+FOyPxTuCGPWJwqFPSKeArbNcpc7wpj1Cc+YmSXCYTdLhMNulgiH3SwRDrtZIhx2s0Q47GaJcNjNEuGwmyXCYTdLhMNulgiH3SwRDrtZIhx2s0Q47GaJcNjNElGklPQWSU/N+HdS0kfdJMKsvxSpQfdcRGyNiK3A24HTwHdwkwizvrLYy/jrgecj4kXcJMKsryw27B8EvpbfLtQkwsyqoXDY88qyNwPfPPe++ZpEuCOMWTUs5sz+XuCJiHg5Xy7UJMIdYcyqYTHpu5X/v4QHN4kw6ytF+7OvBm4Avj1j9d3ADZJ2A+/Jl82sooo2iRgD1p2z7ihuEmHWN4q2f2qLACYX2KYZtTmm+mzZqtWprRwEqX37bDZpTeT/21rN9u23VwImos74AtmYbwq8q2E/S519U2vm3Wbf5MXUFvqLYMvKwJtGePm6Sxi/qD1hV8Ca0RZDPztBbewMcfQ4zZMn27LvXmmMwY5Tv8newSPzbney9dqc93U17BMxwP7JdfNuc2BircOemMlL1nLiunG2Xra/LftrhXjq529mxakLGDw6SGP8LPR52AfGgp8e38jBVRfMu91rzafn3ke7BzWvgGa08VLNloUQ1GotVtan2rK/VoioB1GjvS8NeixCtGKhOfW5j9dvfJslortndrNZKLKz1tSCZ61F8Ic1f43Dbj038PKrrPnxBn767BVt2+fFLwWrX3wVvXaGGDvdtv32M4fdeq659yU2/NtRqNfbts+YmCAmJmk1mxA+zUOXw95CnG4NzrvN6eYK5OcmLa1m37811mmNM8FLx9ZybNV58243PjV3pLsa9rHmII+e3DzvNgdOX8jAGX+qxux1rSZrHz3MipMX0WrMH3a9UpGwT7TqjI4NzbvNsTPnUZ8IX3qZzdDcvZeVu/cuuF0txua8r7ufoDu9guefuHTebepnYeTgRJdGZJaOroZ95eFJtvzD/86/UatFHH+VZvhS3qyduvtFmIkJpl54sZsPaWY5f4LOLBEOu1kiHHazRBQtS/VXkn4h6WlJX5O0UtJmSTsl7ZF0X1591swqqkj7p43AXwLbIuK3gDpZ/fhPA5+NiLcAx4HbOjlQMyun6GX8ALBK0gBwHnAQuA64P7/fHWHMKq5Ir7cDwN8DL5GF/FXgceBERExXGxgFNnZqkGZWXpHL+LVkfd02A5cAq4Ebiz7AzI4wk5xd8kDNrJwil/HvAV6IiCMRMUlWO/5aYCi/rAcYAQ7M9sszO8I0mP8bb2bWOUXC/hJwtaTzJImsVvwzwA+BD+TbuCOMWcUVec2+k2wi7gng5/nvbAc+CXxM0h6yBhL3dnCcZlaSootfOLlAw/FOuYmMWafsjB2cjGOzlpj1J+jMEuGwmyXCYTdLhMNuloiuTtBJOgKMAa907UE77yJ8PFW1nI4Fih3PmyLi4tnu6GrYASQ9FhHbuvqgHeTjqa7ldCxQ/nh8GW+WCIfdLBG9CPv2HjxmJ/l4qms5HQuUPJ6uv2Y3s97wZbxZIroadkk3Snour1t3ZzcfuyxJl0r6oaRn8np8d+TrhyU9Iml3/nNtr8e6GJLqkp6U9GC+3Le1BSUNSbpf0rOSdkm6pp+fn3bXfuxa2CXVgc8D7wXeCtwq6a3devw2mAI+HhFvBa4GPpKP/05gR0RcDuzIl/vJHcCuGcv9XFvwHuDhiLgCuJLsuPry+elI7ceI6Mo/4Brg+zOW7wLu6tbjd+B4vgfcADwHbMjXbQCe6/XYFnEMI2QBuA54EBDZhzYGZnvOqvwPuBB4gXweasb6vnx+yMq87QeGyWpAPgj8fpnnp5uX8dODn9a3deskbQKuAnYC6yPiYH7XIWB9r8a1BJ8DPgFMt8xdR//WFtwMHAG+nL8s+aKk1fTp8xMdqP3oCbpFkrQG+Bbw0Yg4OfO+yP7c9sXbG5LeBxyOiMd7PZY2GQDeBnwhIq4i+1j2r1yy99nzU6r242y6GfYDwMx+zXPWrasqSQ2yoH81Ir6dr35Z0ob8/g3A4V6Nb5GuBW6WtA/4Otml/D0UrC1YQaPAaGSVlSCrrvQ2+vf5KVX7cTbdDPujwOX5bOIKssmGB7r4+KXk9ffuBXZFxGdm3PUAWQ0+6KNafBFxV0SMRMQmsufiBxHxIfq0tmBEHAL2S9qSr5quldiXzw+dqP3Y5UmHm4BfAs8Df9PrSZBFjv1dZJeAPwOeyv/dRPY6dwewG/hPYLjXY13Csb0beDC//WbgJ8Ae4JvAYK/Ht4jj2Ao8lj9H3wXW9vPzA3wKeBZ4GvhXYLDM8+NP0JklwhN0Zolw2M0S4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRPwf7oZsnxjiqTEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(torch.permute(out[0],(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5c79d9e-2085-43fe-a8aa-1591316ab8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bd3c58-8a4e-4a07-b5ec-59748213dcef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
